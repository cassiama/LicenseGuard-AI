# LicenseGuard (Agent)

LicenseGuard is designed to help you easily understand the software licenses of your project's dependencies.

Here's what it offers:

- **Effortless License Checking**: Simply provide your project's `requirements.txt`, and LicenseGuard will analyze it for you.
- **Clear License Identification**: The system identifies the software licenses associated with your dependencies.
- **Understandable Reports**: Get a straightforward JSON report detailing the licenses found, along with a confidence score.
- **Simple Integration**: You can interact with LicenseGuard through a user-friendly API to submit your dependency list and retrieve the analysis results.

LicenseGuard simplifies the process of checking software licenses, giving you a quick and clear picture of your project's licensing landscape.

---

The purpose of this repository to provide AI-powered insights for the [frontend](https://github.com/cassiama/LicenseGuard-UI) when the user provides their analysis result from the backend REST API.

There are two parts:
- the internal AI agent that's responsible for generating a risk report when provided a JSON analysis result
- the front-facing REST API that streams the risk report generated by the internal AI agent

## Quickstart

The fastest and easiest way to get this running on your machine is to use Docker.

### Requirements

In short:

- have Docker Desktop/Engine installed on your local machine
- have an OpenAI API key
- environment variables for connecting to the MCP server's URL

---

Make sure you have Docker Desktop (or Docker Engine) installed on your machine. If you don't, download it from [Docker's website](https://docs.docker.com/get-started/get-docker/).

#### Environment Variables

You will need to provide the following, otherwise you will see errors as you try to use this service:

- `OPENAI_API_KEY`: fairly self-explanatory (if you don't have one, you can get one on the [OpenAI Platform](https://platform.openai.com/api-keys)). Your key should look like this: `sk-proj-<random characters>-<random characters>`
- `MCP_SERVER_HOST`: refers to the host that your MCP server is running on. Your host should be a HTTP/HTTPS domain (e.g. `http://localhost`)
- `MCP_SERVER_PORT`: refers to the port that your MCP server is running on. Your port should be a number from 0 to 65535 (16-bit number) that **doesn't** conflict with a port already in use on the computer. But you should probably just choose `8000` since that's the default port number for the MCP server.

Optionally, for the sake of reproducibility, you can also provide the following environment variables. They provide [LangSmith tracing](https://smith.langchain.com/) so you can view the logs of the agent:
- `LANGCHAIN_TRACING_V2`: a boolean (either `true` or `false`). You  It should look like this: `true`
- `LANGCHAIN_ENDPOINT`: a remote URL that you can access for LangSmith API calls; typically the official LangSmith API URL. It should look like this: `https://api.smith.langchain.com`
- `LANGCHAIN_API_KEY`: a stirng corresponding to the LangSmith API key (provided by LangChain/LangSmith).
- `LANGCHAIN_PROJECT`: a string corresponding to the name of the project. However, if not provided, the project name will be `default`. It should look like this: `LicenseGuard-AI`


### Usage

For the purposes of this guide, we're going to assume that you want to pull the image from Docker Hub. However, you can also download the image from the GitHub Container Registry (GHCR) instead if you'd like.

#### Downloading the Docker Image

Run the following command to download the image from Docker Hub on your machine:

```bash
docker pull licenseguard/license-guard:ai-latest
```

> NOTE: If you want a specific version, then pull the `licenseguard/license-guard:api-v{x.y.z}` image instead (`x.y.z` refers to the [semantic verisoning number](https://semver.org/)).

> NOTE: For those who prefer GHCR, replace any reference to `licenseguard/license-guard` with `ghcr.io/cassiama/license-guard` for any of the commands below, and you'll be good. ðŸ‘ðŸ¿

#### Running the Docker Image

**Run the server** by running the following command (depending on your preference on environment variables):

- **With `.env` file:**
Run the Docker image by running `docker run -p 8001:8001 --env-file .env licenseguard/license-guard:ai-latest` in the terminal.

- **With an environment variable:**
Run the Docker image by running `docker run -p 8001:8001 -e MCP_SERVER_HOST=YOUR_MCP_SERVER_HOST -e MCP_SERVER_PORT=YOUR_MCP_SERVER_PORT -e OPENAI_API_KEY=YOUR_OPENAI_API_KEY licenseguard/license-guard:ai-latest` in the terminal.

> NOTE: This command runs the server in **production** mode, not dev mode.

> NOTE: **You** are responsible for any HTTPS-related concerns. For example, if you are running this behind a TLS Termination Proxy, you need to [add "--proxy-headers" to the `CMD` line in the Dockerfile](https://fastapi.tiangolo.com/deployment/docker/#behind-a-tls-termination-proxy). Please view [FastAPI's documentation on HTTPS](https://fastapi.tiangolo.com/deployment/https/) for more general information on this topic.

You can access the server at `http://localhost:8001`.

Once you have the server running, you can view the documentation by navigating to `http://localhost:8001/docs`.

## Available Routes

For the latest image of the AI microservice on Docker Hub, you can access the following routes: